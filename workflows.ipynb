{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_workflow(workflow_name=\"default\", sheet_name=None, tab_name=None):\n",
    "    \"\"\"Returns a list of namedtuples that define a series of tasks to perform.\"\"\"\n",
    "    \n",
    "    print('Preparing to run workflow: \"%s\".' % workflow_name)\n",
    "\n",
    "    from collections import namedtuple\n",
    "    import sys, os, pickle\n",
    "    import functions\n",
    "    import private\n",
    "    \n",
    "    # First, we define the language we are going to use in constructing workflows.\n",
    "    Configure = namedtuple('Configure', 'message repeat_seconds')\n",
    "    Pipulate  = namedtuple('Pipulate',  'message sheet tab args_tab rows_to_batch chunk_limit extra_data cache')\n",
    "    Populate  = namedtuple('Populate',  'message sheet tab list_of_rows cols rows_to_batch chunk_limit')\n",
    "    Append    = namedtuple('Append',    'message sheet tab list_of_rows')\n",
    "\n",
    "    # Next, we get the Google Sheet and Tab name from user, setting it as the default for future runs.\n",
    "    \n",
    "    #if workflow_name in ['default', 'throttled', 'dribble', 'test'] and not sheet_name and not tab_name:\n",
    "    default_sheet, default_tab = None, None\n",
    "    if os.path.isfile(\"defaults.pkl\"):\n",
    "        defaults = pickle.load(open(\"defaults.pkl\", \"rb\"))\n",
    "        default_sheet = defaults['sheet_name']\n",
    "        default_tab = defaults['tab_name']\n",
    "    if default_sheet:\n",
    "        sheet_name = input(\"Google Sheet name (or hit Enter to use %s): \" % default_sheet) or default_sheet\n",
    "    else:\n",
    "        sheet_name = input(\"Google Sheet name: \")\n",
    "    print(\"Sheet: %s\" % sheet_name)\n",
    "    if default_tab:\n",
    "        tab_name = input(\"Google Tab name (or hit Enter to use %s): \" % default_tab) or default_tab\n",
    "    else:\n",
    "        tab_name = input(\"Google Tab name: \")\n",
    "    print(\"Tab: %s\" % tab_name)\n",
    "    #End if-indent\n",
    "    \n",
    "    defaults = {\"sheet_name\": sheet_name, \"tab_name\": tab_name}\n",
    "    pickle.dump(defaults, open(\"defaults.pkl\", \"wb\"))\n",
    "\n",
    "    # Thirdly, we set a bunch of local values that will help us write our workflows.\n",
    "    dates = functions.common_date_boundaries()\n",
    "    start = dates.start_30_days\n",
    "    end = dates.end_30_days\n",
    "    site = private.site  # <-- Site URL for seoinit\n",
    "    gaid = private.gaid  # <-- Google Analytics ID for seoinit\n",
    "    feed = private.feed  # <-- Atom Feed for feedmonitor\n",
    "    feed_sheet = private.feed_sheet\n",
    "    google_search_console = \"functions.populate_from_gsc('%s', '%s', '%s')\" % (site, start, end)\n",
    "    google_analytics = \"functions.populate_from_ga('%s','ga:%s', '%s', '%s')\" % (site, gaid, start, end)\n",
    "    one_page_crawl = \"functions.one_page_crawl('%s')\" % (site)\n",
    "    atom_feed = \"functions.populate_from_atom('%s', 'Feed', '%s')\" % (feed_sheet, feed)\n",
    "\n",
    "    # Lastly, we create a bunch of different workflows we can choose from.\n",
    "    workflows = {\n",
    "        \"default\":[  \n",
    "            Pipulate(\n",
    "                message=\"Workflow: default - Pipulating 5 rows at a time up to 1000.\",\n",
    "                sheet=sheet_name,\n",
    "                tab=tab_name,\n",
    "                args_tab=\"kwargs\",\n",
    "                rows_to_batch=5,\n",
    "                chunk_limit=200,\n",
    "                extra_data=None,\n",
    "                cache=False,\n",
    "            )\n",
    "        ],\n",
    "        \"onerow\":[  \n",
    "            Pipulate(\n",
    "                message=\"Workflow: onerow - Processing just 1 row then stopping.\",\n",
    "                sheet=sheet_name,\n",
    "                tab=tab_name,\n",
    "                args_tab=\"kwargs\",\n",
    "                rows_to_batch=3,\n",
    "                chunk_limit=1,\n",
    "                extra_data=None,\n",
    "                cache=False,\n",
    "            )\n",
    "        ],\n",
    "        \"dribble\":[  \n",
    "            Configure(\n",
    "                message=\"Workflow: dribble = Processing 9 rows every 11 minutes.\",\n",
    "                repeat_seconds=660\n",
    "            ),\n",
    "            Pipulate(\n",
    "                message=\"Dribbling.\",\n",
    "                sheet=sheet_name,\n",
    "                tab=tab_name,\n",
    "                args_tab=\"kwargs\",\n",
    "                rows_to_batch=9,\n",
    "                chunk_limit=1,\n",
    "                extra_data=None,\n",
    "                cache=False,\n",
    "            )\n",
    "        ],\n",
    "        \"tests\":[  \n",
    "            Populate(\n",
    "                message=\"Establish that we have Internet connectivity and can fully resolve http requests.\",\n",
    "                sheet=\"Tests\",\n",
    "                tab=\"Sheet1\",\n",
    "                list_of_rows = 'functions.topsites()',\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=0\n",
    "            ),\n",
    "            Pipulate(\n",
    "                message=\"Default: Processing 20 updates of 50 rows at a time (1000 rows total).\",\n",
    "                sheet=\"Tests\",\n",
    "                tab=\"Sheet1\",\n",
    "                args_tab=None,\n",
    "                rows_to_batch=5,\n",
    "                chunk_limit=5,\n",
    "                extra_data=None,\n",
    "                cache=False,\n",
    "            )\n",
    "        ],\n",
    "        \"seoinit\":[\n",
    "            Populate(\n",
    "                message=\"SEOInit: Caries out SEO site audit, using Google Analytics & Search Console access.\",\n",
    "                sheet=sheet_name,\n",
    "                tab=\"GSC\",\n",
    "                list_of_rows = google_search_console,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            ),\n",
    "            Populate(\n",
    "                message=None,\n",
    "                sheet=sheet_name,\n",
    "                tab=\"GA\",\n",
    "                list_of_rows = google_analytics,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            ),\n",
    "            Populate(\n",
    "                message=None,\n",
    "                sheet=sheet_name,\n",
    "                tab=\"Crawl\",\n",
    "                list_of_rows = one_page_crawl,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            )\n",
    "        ],\n",
    "        \"gsc\":[\n",
    "            Populate(\n",
    "                message=\"GSC: Pulls last 30 days of Google Search Console data.\",\n",
    "                sheet=sheet_name,\n",
    "                tab=\"GSC\",\n",
    "                list_of_rows = google_search_console,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            )\n",
    "        ],\n",
    "        \"quickcrawl\":[\n",
    "            Populate(\n",
    "                message=\"QuickCrawl: Grabs all onsite links from a page of site (usually homepage).\",\n",
    "                sheet=sheet_name,\n",
    "                tab=\"Crawl\",\n",
    "                list_of_rows = one_page_crawl,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            )\n",
    "        ],\n",
    "        \"feedmonitor\":[\n",
    "            Configure(\n",
    "                message=\"FeedMonitor: Checks ATOM feed and appends new items to bottom of spreadsheet.\",\n",
    "                repeat_seconds=660\n",
    "            ),\n",
    "            Append(\n",
    "                message=\"Appending rows to the Feed Monitor sheet.\",\n",
    "                sheet=feed_sheet,\n",
    "                tab=\"Feed\",\n",
    "                list_of_rows = atom_feed,\n",
    "            ),\n",
    "            Pipulate(\n",
    "                message=\"Pipulating the newly added rows.\",\n",
    "                sheet=feed_sheet,\n",
    "                tab=\"Feed\",\n",
    "                args_tab=\"kwargs\",\n",
    "                rows_to_batch=5,\n",
    "                chunk_limit=200,\n",
    "                extra_data=None,\n",
    "                cache=False,\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "    workflow = workflows[workflow_name]\n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
