{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c98ce7eb-691d-4682-9243-d0b1cd1eb1b2"
    }
   },
   "source": [
    "# Learn Python while advancing your SEO skills with Pipulate\n",
    "    Pipulate is a system for scheduled and ad hoc SEO jobs and tasks that runs under Jupyter Notebook.\n",
    "    Jupyter Notebook is an environment for easily distributing, sharing and running programming code.\n",
    "    This combines the power of your desktop with the best of the generally server-based tools around.\n",
    "    It might take some work to get going, but once you do, your life in SEO will never be the same.\n",
    "    Get started by downloading and installing the Python 3.5 version of Anaconda for your desktop OS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "f5687a2a-5ee6-4760-bac3-afe750daa362"
    }
   },
   "source": [
    "## Global Imports & Google Login (*Don't change*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7dd454e5-19a7-4547-9834-f5a23bd88471"
    }
   },
   "outputs": [],
   "source": [
    "# First, we get logging going. Double-imports are sometimes necessary under Jupyter Notebook.\n",
    "from imp import reload\n",
    "import logging; reload(logging); logger = logging.getLogger()\n",
    "logging.basicConfig(filename='debug.log', level=logging.CRITICAL)\n",
    "\n",
    "# Next, we load all the standard and 3rd party libraries which we want to be globally available.\n",
    "import re, sys, os, pickle, shelve\n",
    "from collections import namedtuple, OrderedDict\n",
    "import requests\n",
    "\n",
    "# Thirdly, we enable .ipynb files to be imported AS Python modules (as if they were .py files).\n",
    "import notebook_finder\n",
    "import goodsheet; reload(goodsheet); import goodsheet\n",
    "import functions; reload(functions); import functions\n",
    "\n",
    "# Lastly, we import everything that you want to keep private from a file not in the git repo.\n",
    "import private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "10a8b924-6ba5-4638-ae57-b8a366b491c6"
    }
   },
   "source": [
    "## Workflows (*Study, then change*)\n",
    "1. Workflows control everything with Pipulate. A one-time job is a workflow. A scheduled task is a workflow.\n",
    "2. The standard workflow is named \"default\", and using the default workflow is how you should get started.\n",
    "3. If you simply run Pipulate (select Kernel / Restart & Run All), you will be using the default workflow.\n",
    "4. The default workflow will prompt you for a Google Sheet and the Tab name that you want to process.\n",
    "5. After studying these examples of common SEO needs, you can design your own custom workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0f511084-52a0-4cd2-bff4-310cd83cef33"
    }
   },
   "outputs": [],
   "source": [
    "workflow_name = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0214a0dd-475b-4b84-b4f5-55b529023ef9"
    }
   },
   "outputs": [],
   "source": [
    "def get_workflow(workflow_name=\"default\", sheet_name=None, tab_name=None):\n",
    "\n",
    "    # First, we define the language we are going to use in constructing workflows.\n",
    "    Configure = namedtuple('Configure', 'repeat_seconds')\n",
    "    Pipulate = namedtuple('Pipulate', 'sheet tab args_tab rows_to_batch chunk_limit extra_data cache')\n",
    "    Populate = namedtuple('Populate', 'sheet tab list_of_rows cols rows_to_batch chunk_limit')\n",
    "    Append   = namedtuple('Append', 'sheet tab list_of_rows')\n",
    "\n",
    "    # Next, we get the Google Sheet and Tab name from user, setting it as the default for future runs.\n",
    "    if workflow_name in ['default', 'throttled'] and not sheet_name and not tab_name:\n",
    "        if os.path.isfile(\"defaults.pkl\"):\n",
    "            defaults = pickle.load(open(\"defaults.pkl\", \"rb\"))\n",
    "            default_sheet = defaults['sheet_name']\n",
    "            default_tab = defaults['tab_name']\n",
    "        if default_sheet:\n",
    "            sheet_name = input(\"Google Sheet name (or hit Enter to use %s): \" % default_sheet) or default_sheet\n",
    "        else:\n",
    "            sheet_name = input(\"Google Sheet name: \")\n",
    "        if default_tab:\n",
    "            tab_name = input(\"Google Tab name (or hit Enter to use %s): \" % default_tab) or default_tab\n",
    "        else:\n",
    "            tab_name = input(\"Google Tab name: \")\n",
    "    defaults = {\"sheet_name\": sheet_name, \"tab_name\": tab_name}\n",
    "    pickle.dump(defaults, open(\"defaults.pkl\", \"wb\"))\n",
    "\n",
    "    # Thirdly, we set a bunch of local values that will help us write our workflows.\n",
    "    dates = functions.common_date_boundaries()\n",
    "    start = dates.start_30_days\n",
    "    end = dates.end_30_days\n",
    "    site = private.site  # <-- Site URL for seoinit\n",
    "    gaid = private.gaid  # <-- Google Analytics ID for seoinit\n",
    "    feed = private.feed  # <-- Atom Feed for feedmonitor\n",
    "    feed_sheet = private.feed_sheet\n",
    "    google_search_console = \"functions.populate_from_gsc('%s', '%s', '%s')\" % (site, start, end)\n",
    "    google_analytics = \"functions.populate_from_ga('%s','ga:%s', '%s', '%s')\" % (site, gaid, start, end)\n",
    "    one_page_crawl = \"functions.one_page_crawl('%s')\" % (site)\n",
    "    atom_feed = \"functions.populate_from_atom('%s', 'Feed', '%s')\" % (feed_sheet, feed)\n",
    "\n",
    "    # Lastly, we create a bunch of different workflows we can choose from.\n",
    "    workflows = {\n",
    "        \"default\":[  \n",
    "            Pipulate(\n",
    "                sheet=sheet_name,\n",
    "                tab=tab_name,\n",
    "                args_tab=None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=20,\n",
    "                extra_data=None,\n",
    "                cache=False,\n",
    "            )\n",
    "        ],\n",
    "        \"throttled\":[  \n",
    "            Pipulate(\n",
    "                sheet=sheet_name,\n",
    "                tab=tab_name,\n",
    "                args_tab=None,\n",
    "                rows_to_batch=5,\n",
    "                chunk_limit=1,\n",
    "                extra_data=None,\n",
    "                cache=False,\n",
    "            )\n",
    "        ],\n",
    "        \"seoinit\":[\n",
    "            Populate(\n",
    "                sheet=sheet_name,\n",
    "                tab=\"GSC\",\n",
    "                list_of_rows = google_search_console,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            ),\n",
    "            Populate(\n",
    "                sheet=sheet_name,\n",
    "                tab=\"GA\",\n",
    "                list_of_rows = google_analytics,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            ),\n",
    "            Populate(\n",
    "                sheet=sheet_name,\n",
    "                tab=\"Crawl\",\n",
    "                list_of_rows = one_page_crawl,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            )\n",
    "        ],\n",
    "        \"quickcrawl\":[\n",
    "            Populate(\n",
    "                sheet=sheet_name,\n",
    "                tab=\"Crawl\",\n",
    "                list_of_rows = one_page_crawl,\n",
    "                cols = None,\n",
    "                rows_to_batch=50,\n",
    "                chunk_limit=None\n",
    "            )\n",
    "        ],\n",
    "        \"feedmonitor\":[\n",
    "            Configure(repeat_seconds=3600),\n",
    "            Append(\n",
    "                sheet=feed_sheet,\n",
    "                tab=\"Feed\",\n",
    "                list_of_rows = atom_feed,\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    "    workflow = workflows[workflow_name]\n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "78574e16-e032-4af8-9626-61c010dffb96"
    }
   },
   "source": [
    "## Debugging Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6533e913-587c-4219-8097-06b6765eb7ba"
    }
   },
   "outputs": [],
   "source": [
    "def error(exception_info, stop=True, info=None):\n",
    "    \"\"\"Prints informative error and stops execution unless optional stop argument is False.\"\"\"\n",
    "    exception_type, description, traceback = exception_info\n",
    "    errorname = exception_type.__name__\n",
    "    filename = os.path.split(traceback.tb_frame.f_code.co_filename)[1]\n",
    "    linenumber = traceback.tb_lineno\n",
    "    if info:\n",
    "        description = info\n",
    "    print(\"ERROR: %s: %s in %s line %s\" % (errorname, description, filename, linenumber))\n",
    "    logger.exception(\"ERROR:\")\n",
    "    if stop:\n",
    "        raise SystemExit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c0b3971e-8919-40f9-be8a-ace261cd8d5d"
    }
   },
   "source": [
    "## The Pipulate() Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "466300ff-b829-4eb5-a8db-1ac00c6afd4c"
    }
   },
   "outputs": [],
   "source": [
    "def pipulate(google_sheet_name, google_sheet_tab, tab_with_args=None, rows_to_batch=50, \n",
    "             chunk_limit=None, data=None, cache=True):\n",
    "    \"\"\"Update all cells in Google Sheet where columns are named with pipulate functions.\n",
    "    \n",
    "    The pipulate function is defines the conventional behavior of using GSheets for I/O.\n",
    "    It scans from left-to-right and top-to-bottom of a Google Sheet, finding \"requests\".\n",
    "    Requests are empty cells in columns labeled with function names found in functions module.\n",
    "    Pipulate will execute the named function using values from that row as function arguments.\n",
    "    The entire row's contents are fed into the named function as key/value pairs as **kwargs.\n",
    "    If **kwargs proves to be too messy, decorators like @url can clean up the passed-in args.\n",
    "    Results are batched-up and the sheet updated on every \"rows_to_batch\" number of rows.\n",
    "    Because pipulate works against pre-existing rows, we must often create some rows first.\n",
    "    More complex workflows can chain-up a series of row-creations and subsequent pipulations.\"\"\"\n",
    "    \n",
    "    if not google_sheet_tab and not google_sheet_name:\n",
    "        print(\"A Google Sheet and Tab name must be set. Please set and re-run.\")\n",
    "        raise SystemExit()\n",
    "    \n",
    "    # Create connection to GSheets, gather important details, and fail immediately on trouble.\n",
    "    print('Examining \"%s\" in \"%s\"...' % (google_sheet_tab, google_sheet_name))\n",
    "    try:\n",
    "        worksheet = goodsheet.oauth().open(google_sheet_name).worksheet(google_sheet_tab)\n",
    "        rows = worksheet.row_count\n",
    "        cols = worksheet.col_count\n",
    "        end_range = worksheet.get_addr_int(rows, cols)\n",
    "    except:\n",
    "        error(sys.exc_info())\n",
    "    \n",
    "    # Make a grab for additional key/value pair arguments (like API keys) from optional tab.\n",
    "    arg_dict = {}\n",
    "    arg_cells = None\n",
    "    if tab_with_args:\n",
    "        print('Looking for optional key/value pairs in \"%s\" tab...' % (tab_with_args))\n",
    "        try:\n",
    "            arg_sheet = goodsheet.oauth().open(google_sheet_name).worksheet(tab_with_args)     \n",
    "            arg_cells = arg_sheet.range(\"A1:B20\")\n",
    "        except:\n",
    "            error(sys.exc_info())\n",
    "    if arg_cells:\n",
    "        arg_temp = None\n",
    "        for an_arg in arg_cells:\n",
    "            if an_arg.value:\n",
    "                if an_arg.col == 1:\n",
    "                    arg_temp = an_arg.value\n",
    "                else:\n",
    "                    if an_arg.value:\n",
    "                        arg_dict[arg_temp] = an_arg.value\n",
    "                    else:\n",
    "                        arg_dict[arg_temp] = None\n",
    "                        arg_temp = None\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Create dictionary of pipulate functions invokable using their string-names dict keys!\n",
    "    pipulate_funcs = [x for x in dir(functions) if x[0] is not '_']\n",
    "    func_dict = {x.lower():eval('functions.%s' % x) for x in pipulate_funcs}\n",
    "\n",
    "    # Create list of all the values found in the 1st row so we can identify named functions.\n",
    "    row1_range = 'A1:%s' % worksheet.get_addr_int(1, cols)\n",
    "    cell_range = worksheet.range(row1_range)\n",
    "    col_names = [x.value.lower() for x in cell_range]\n",
    "\n",
    "    # Find the first blank row in the sheet so we can always efficiently start in the right place.\n",
    "    list_of_rows = worksheet.get_all_values() #Expensive but worth it \n",
    "    first_row_with_blank = rows #Default to end-of-sheet, unless actual blanks are found.\n",
    "    if not list_of_rows:\n",
    "        print(\"Error: Sheet empty. Please set initial values.\")\n",
    "        raise SystemExit()\n",
    "    if len(list_of_rows) == 1:\n",
    "        first_row_with_blank = 2 #If we only find 1 row (at all), then row 2 MUST be 1st blank.\n",
    "    for row_dex, arow in enumerate(list_of_rows):\n",
    "        for cell_dex, acell in enumerate(arow):\n",
    "            if not acell and cell_range[cell_dex].value in func_dict: #Blank must be in func col.\n",
    "                first_row_with_blank = row_dex+1\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    list_of_rows = None #Blank no longer necessary potentially large object (be kind to memory)\n",
    "    \n",
    "    # Chunk the sheet into a series of ranges that will be used for batch-updates\n",
    "    chunk_ranges = [(x+1, x+rows_to_batch+1) for x in list(range(rows-1)) if x%rows_to_batch == 0]\n",
    "    chunks_to_go = [(x,y) for x,y in chunk_ranges if y > first_row_with_blank]\n",
    "    \n",
    "    # Pipulate each chunk\n",
    "    for chunk_dex, (row_start, row_end) in enumerate(chunks_to_go):\n",
    "        if chunk_limit > 0 and chunk_dex >= chunk_limit:\n",
    "            break\n",
    "        \n",
    "        # Convert each chunk into Excel-like A2:B2 range notation\n",
    "        top_left = worksheet.get_addr_int(row_start+1, 1)\n",
    "        lower_right = worksheet.get_addr_int(row_end, cols)\n",
    "        range_string = \"%s:%s\" % (top_left, lower_right)\n",
    "        \n",
    "        # Calculate correct number of rows in the last (likely) uneven chunk\n",
    "        if chunk_dex+1 == len(chunk_ranges):\n",
    "            range_string = \"%s:%s\" % (top_left, end_range)\n",
    "        print(\"Pipulating range %s of %s (%s)\" % (chunk_dex+1, len(chunks_to_go), range_string))\n",
    "        print(\"%s updating in: \" % range_string, end=\"\")\n",
    "\n",
    "        # Use chunk range to create new GSpread worksheet obj for writing-back response values.\n",
    "        try:\n",
    "            chunk_range = worksheet.range(range_string)\n",
    "        except:\n",
    "            error(sys.exc_info())\n",
    "            \n",
    "        # Step through each cell in the current chunk.\n",
    "        row_dict = OrderedDict() #Will contain all values from row and be passed to function as **kwargs\n",
    "        count_down = int(len(chunk_range)/cols)+1\n",
    "        for cell_dex, acell in enumerate(chunk_range): #Working with cells, but interested in rows\n",
    "            row, col, val = acell.row, acell.col, acell.value\n",
    "            # Now we pipulate this row's row_dict with column-name/cell-value pairs\n",
    "            row_dict[col_names[col-1]] = val\n",
    "            if col%cols == 0: #This is how we determine reaching last cell of row\n",
    "                count_down = count_down - 1\n",
    "                print(\"%s, \" % count_down, end=\"\")\n",
    "                requests_response = None #HTML-cache object loop-leak prevention\n",
    "                Response = None #Function-return loop-leak prevention\n",
    "                # Why fetch the HTML for a URL more than once, if you don't have to?\n",
    "                if 'url' in row_dict:\n",
    "                    with shelve.open('urls') as urls:\n",
    "                        if cache == True and row_dict['url'] in urls.keys():\n",
    "                            requests_response = urls[row_dict['url']]\n",
    "                        else:\n",
    "                            try:\n",
    "                                requests_response = requests.get(row_dict['url'])\n",
    "                                urls[row_dict['url']] = requests_response #The moment of pickling\n",
    "                            except requests.exceptions.RequestException as e:\n",
    "                                print(\"(bad url) \", end=\"\")\n",
    "                                continue\n",
    "                        # We now make the ENTIRE response object available to pipulate functions.\n",
    "                        row_dict['response'] = requests_response\n",
    "                # If data exists, we make it mutably available (for memory) to every row\n",
    "                if data:\n",
    "                    row_dict['data'] = data\n",
    "                for index, (key, val) in enumerate(row_dict.items()):\n",
    "                    if not val: #Only process empty cells in function-named columns\n",
    "                        if key in [x.lower() for x in dir(functions) if x[0] is not '_']:\n",
    "                            if arg_dict:\n",
    "                                row_dict = OrderedDict(**arg_dict, **row_dict)\n",
    "                            try:\n",
    "                                Response = func_dict[key](**row_dict) #pipulate!\n",
    "                            except:\n",
    "                                error(sys.exc_info(), info=key)\n",
    "                            # We pipulate at end-of-row but update back to earlier cells from row.\n",
    "                            row_start = cell_dex-cols+1\n",
    "                            func_dex = col_names.index(key)\n",
    "                            update_cell = row_start + func_dex\n",
    "                            if Response:\n",
    "                                if Response.ok:\n",
    "                                    chunk_range[update_cell].value = Response.text #uncommitted\n",
    "                                    row_dict[key] = Response.text # For sequential column dependencies\n",
    "                                else:\n",
    "                                    chunk_range[update_cell].value = \"Err: %s\" % Response.status_code\n",
    "                            else:\n",
    "                                print(\"Pipulate funcs must return Response object. Check %s.\" % key)\n",
    "                                error(sys.exc_info(), info=key)\n",
    "        try:\n",
    "            # Batch update Google Sheets with the modified chunk_range.\n",
    "            worksheet.update_cells(chunk_range)\n",
    "            print(\"Range updated!\")\n",
    "        except:\n",
    "            error(sys.exc_info())\n",
    "    print(\"Pipulation complete!\") #do a little dance\n",
    "    worksheet = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5a06584b-8163-44c5-91b7-ae97a0ddb976"
    }
   },
   "source": [
    "## The Populate() Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "15899185-a456-47f8-a9c3-40656cc51da0"
    }
   },
   "outputs": [],
   "source": [
    "def populate(sheet, tab, therows, cols=None, rows_to_batch=50, chunk_limit=None):\n",
    "    \"\"\"Creates a new Tab in Google Sheet. Still must add chunking support.\"\"\"\n",
    "    print('Checking for \"%s\" in \"%s\"...' % (tab, sheet))\n",
    "    if type(therows) is str:\n",
    "        therows = eval(therows)\n",
    "    elif type(therows) is not list:\n",
    "        print(\"list_of_rows must be a list of lists or string that will eval to one.\")\n",
    "        raise SystemExit()\n",
    "    try:\n",
    "        spread = goodsheet.oauth().open(sheet)\n",
    "        list_of_sheets = spread.worksheets()\n",
    "    except:\n",
    "        error(sys.exc_info())\n",
    "    sheets = [x.title for x in list_of_sheets]    \n",
    "    list_of_lists = therows\n",
    "    if cols and len(cols) == len(rows[0]):\n",
    "        headers = [cols]\n",
    "        list_of_lists = headers + rows\n",
    "    rows = len(list_of_lists)\n",
    "    cols = len(list_of_lists[0])\n",
    "    try:\n",
    "        if tab not in sheets:\n",
    "            print(\"Creating %s tab...\" % tab)\n",
    "            spread.add_worksheet(tab, rows, cols)\n",
    "            worksheet = goodsheet.oauth().open(sheet).worksheet(tab)\n",
    "        else:\n",
    "            print(\"Resetting %s tab...\" % tab)\n",
    "            worksheet = goodsheet.oauth().open(sheet).worksheet(tab)\n",
    "            worksheet.resize(rows=2, cols=cols)\n",
    "            end_row_two = worksheet.get_addr_int(2,cols)\n",
    "            blank_range = \"A2:%s\" % end_row_two\n",
    "            cells_to_blank = worksheet.range(blank_range)\n",
    "            for a_cell in cells_to_blank:\n",
    "                a_cell.value = ''\n",
    "            worksheet.update_cells(cells_to_blank)\n",
    "            worksheet.resize(rows=rows, cols=cols)\n",
    "        end_range = worksheet.get_addr_int(rows, cols)\n",
    "    except:\n",
    "        error(sys.exc_info())\n",
    "    range_string = \"A1:%s\" % end_range\n",
    "    chunk_range = worksheet.range(range_string)\n",
    "    flat_list = [item for sublist in list_of_lists for item in sublist]\n",
    "    chunk_ranges = [(x+1, x+rows_to_batch+1) for x in list(range(rows-1)) if x%rows_to_batch == 0]\n",
    "    for chunk_dex, (row_start, row_end) in enumerate(chunk_ranges):\n",
    "        if chunk_limit > 0 and chunk_dex >= chunk_limit:\n",
    "            break\n",
    "    \n",
    "        # Convert each chunk into Excel-like A2:B2 range notation\n",
    "        top_left = worksheet.get_addr_int(row_start, 1)\n",
    "        lower_right = worksheet.get_addr_int(row_end, cols)\n",
    "        range_string = \"%s:%s\" % (top_left, lower_right)\n",
    "        #print((top_left, lower_right, range_string))\n",
    "\n",
    "        # Calculate correct number of rows in the last (likely) uneven chunk\n",
    "        if chunk_dex+1 == len(chunk_ranges):\n",
    "            range_string = \"%s:%s\" % (top_left, end_range)\n",
    "\n",
    "        # Use chunk range to create new GSpread worksheet obj for writing-back response values.\n",
    "        try:\n",
    "            chunk_range = worksheet.range(range_string)\n",
    "        except:\n",
    "            error(sys.exc_info())\n",
    "\n",
    "        # Step through each cell in the current chunk.\n",
    "        for cell_dex, acell in enumerate(chunk_range): #Working with cells, but interested in rows\n",
    "            row, col, val = acell.row, acell.col, acell.value\n",
    "            flat_cell_to_update = row*cols-(cols-col)-1\n",
    "            #print((flat_cell_to_update, flat_list[flat_cell_to_update]))\n",
    "            acell.value =  flat_list[flat_cell_to_update]\n",
    "        try:\n",
    "            # Batch update Google Sheets with the modified chunk_range.\n",
    "            worksheet.update_cells(chunk_range)\n",
    "            print(\"Range %s of %s updated!\" % (chunk_dex+1, len(chunk_ranges)))\n",
    "        except:\n",
    "            error(sys.exc_info())\n",
    "            \n",
    "    print(\"%s in %s populated.\" % (tab, sheet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0f9808c5-e9dd-44e2-8ace-c3b481fa341f"
    }
   },
   "source": [
    "## The Append() Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ab879d2b-f844-4883-a752-0038d1f7c382"
    }
   },
   "outputs": [],
   "source": [
    "def append(sheet, tab, therows):\n",
    "    print('Checking for \"%s\" in \"%s\"...' % (tab, sheet))\n",
    "    if type(therows) is str:\n",
    "        therows = eval(therows)\n",
    "    elif type(therows) is not list:\n",
    "        print(\"list_of_rows must be a list of lists or string that will eval to one.\")\n",
    "        raise SystemExit()\n",
    "    if not therows:\n",
    "        print(\"No rows to append.\")\n",
    "        return\n",
    "    try:\n",
    "        spread = goodsheet.oauth().open(sheet)\n",
    "        list_of_sheets = spread.worksheets()\n",
    "    except:\n",
    "        error(sys.exc_info())\n",
    "    sheets = [x.title for x in list_of_sheets]    \n",
    "    if tab in sheets:\n",
    "        print('Appending to \"%s\" in \"%s\"...' % (tab, sheet))\n",
    "        try:\n",
    "            worksheet = goodsheet.oauth().open(sheet).worksheet(tab)\n",
    "            rows = worksheet.row_count\n",
    "            cols = worksheet.col_count\n",
    "            append_width = len(therows[0])\n",
    "            append_rows = len(therows)\n",
    "            begin_range = worksheet.get_addr_int(rows+1, 1)\n",
    "            end_range = worksheet.get_addr_int(rows+append_rows, cols)\n",
    "        except:\n",
    "            error(sys.exc_info())\n",
    "        if append_width != cols:\n",
    "            print(\"The %s tab must be the same width as the list_of_lists you're trying to append.\" % tab)\n",
    "            raise SystemExit()\n",
    "        new_size = rows + append_rows\n",
    "        try:\n",
    "            worksheet.resize(rows=new_size, cols=cols)\n",
    "        except:\n",
    "            error(sys.exc_info())\n",
    "        range_string = \"%s:%s\" % (begin_range, end_range)\n",
    "        cell_list = worksheet.range(range_string)\n",
    "        flat_list = [item for sublist in therows for item in sublist]\n",
    "        for cell_dex, acell in enumerate(cell_list): #Working with cells, but interested in rows\n",
    "            acell.value =  flat_list[cell_dex]\n",
    "        try:\n",
    "            worksheet.update_cells(cell_list)\n",
    "            print(\"List appended!\")\n",
    "        except:\n",
    "            error(sys.exc_info())\n",
    "    else:\n",
    "        print(\"%s tab not found. Appending only works when there is a pre-existing table.\" % tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3e84c663-6aa9-4716-a217-7df183217c49"
    }
   },
   "source": [
    "## Schedulable Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "9aa050ad-d222-44ac-bdc5-a49027630bd2"
    }
   },
   "outputs": [],
   "source": [
    "def schedule_me(workflow):\n",
    "    goodsheet.oauth()\n",
    "    print(\"WORKFLOW BEGINNING\")\n",
    "    repeat_seconds = None\n",
    "    for a_tuple in workflow:\n",
    "        tuple_name = type(a_tuple).__name__\n",
    "        if tuple_name == 'Configure':\n",
    "            print(\"Cofiguration Found (scheduling).\")\n",
    "            repeat_seconds = a_tuple.repeat_seconds\n",
    "        elif tuple_name == 'Pipulate':\n",
    "            print(\"Pipulate request being processed...\")\n",
    "            sheet, tab, args_tab, data, cache, rows_to_batch, chunk_limit = a_tuple\n",
    "            pipulate(sheet, tab, args_tab, data, cache, rows_to_batch, chunk_limit) #consider splatting\n",
    "        elif tuple_name == 'Populate':\n",
    "            print(\"Populate request being processed...\")\n",
    "            sheet, tab, list_of_rows, cols, rows_to_batch, chunk_limit = a_tuple\n",
    "            populate(sheet, tab, list_of_rows, cols, rows_to_batch, chunk_limit)\n",
    "        elif tuple_name == 'Append':\n",
    "            print(\"Append request being processed...\")\n",
    "            sheet, tab, list_of_rows = a_tuple\n",
    "            append(sheet, tab, list_of_rows)\n",
    "    print(\"WORKFLOW COMPLETE!\")\n",
    "    if repeat_seconds:\n",
    "        goodsheet.oauth()\n",
    "        print(\"Setting a %s second loop for next run of this workflow.\" % repeat_seconds)\n",
    "        import sched, time\n",
    "        scheduler = sched.scheduler(timefunc=time.time, delayfunc=time.sleep)\n",
    "        scheduler.enter(delay=repeat_seconds, priority=1, action=schedule_me, argument=(workflow,))\n",
    "        scheduler.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "17a7dc4d-aab2-49ad-866c-151ac5b6b9ce"
    }
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "cd6c8eba-c3b8-46f8-a7fa-d264c9a8cde9"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"You are logged in as %s\" % goodsheet.get_email())\n",
    "    schedule_me(get_workflow(workflow_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%tb"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
